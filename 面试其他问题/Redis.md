# Redis

## 简介

> 简单来说 redis 就是一个数据库，不过与传统数据库不同的是 redis 的数据是存在内存中的，所以读写速度非常快，因此 redis 被广泛应用于缓存方向。另外，redis 也经常用来做分布式锁。redis 提供了多种数据类型来支持不同的业务场景。除此之外，redis 支持事务 、持久化、LUA脚本、LRU驱动事件、多种集群方案。
>
> **注： redis中的value内部可以支持各种数据结构类型，比如可以存入一个普通的string，还可以存list，set，hashmap，sortedSet（有序的set）**

## 应用场景

- 用来做缓存（ehcache/memcached）--redis的所有数据时放在内存中的（内存数据库）
- 可以在某些特定应用场景下替代传统数据库--比如社交类的应用
- 在一些大型系统中，巧妙地使用一些特定的功能：session共享、购物车

## 特性

> redis数据访问速度快（数据在内存中）
> redis有数据持久化机制（持久化机制有两种：1、定期将内存数据dump到磁盘；2、aof（append only file）持久化机制--用记日志的方式记录每一条数据更新操作，一旦出现灾难事件，可以通过日志重放来恢复整个数据库）
> redis支持集群模式（容量可以线程扩展）
> redis相比其他缓存工具（ehcach/memcached），有一个鲜明的优势，支持丰富的数据结构。

## 为什么要用缓存？

用缓存，主要有两个用途：**高性能**、**高并发**。

### 高性能

> 假设这么个场景，你有个操作，一个请求过来，吭哧吭哧你各种乱七八糟操作 mysql，半天查出来一个结果，耗时 600ms。但是这个结果可能接下来几个小时都不会变了，或者变了也可以不用立即反馈给用户。那么此时咋办？
>
> 缓存啊，折腾 600ms 查出来的结果，扔缓存里，一个 key 对应一个 value，下次再有人查，别走 mysql 折腾 600ms 了，直接从缓存里，通过一个 key 查出来一个 value，2ms 搞定。性能提升 300 倍。
>
> 就是说对于一些需要复杂操作耗时查出来的结果，且确定后面不怎么变化，但是有很多读请求，那么直接将查询出来的结果放在缓存中，后面直接读缓存就好。

### 高并发

> mysql 这么重的数据库，压根儿设计不是让你玩儿高并发的，虽然也可以玩儿，但是天然支持不好。mysql 单机支撑到 `2000QPS` 也开始容易报警了。
>
> 所以要是你有个系统，高峰期一秒钟过来的请求有 1万，那一个 mysql 单机绝对会死掉。你这个时候就只能上缓存，把很多数据放缓存，别放 mysql。缓存功能简单，说白了就是 `key-value` 式操作，单机支撑的并发量轻松一秒几万十几万，支撑高并发 so easy。单机承载并发量是 mysql 单机的几十倍。

**缓存是走内存的，内存天然就支撑高并发。**

## redis 和 memcached 的区别

> 1. **性能对比：**
>    由于 redis 只使用单核，而 memcached 可以使用多核，所以平均每一个核上 redis 在存储小数据时比 memcached 性能更高。而在 100k 以上的数据中，memcached 性能要高于 redis，虽然 redis 最近也在存储大数据的性能上进行优化，但是比起 memcached，还是稍有逊色。
> 2. **为啥 redis 单线程模型也能效率这么高？**
>    - 纯内存操作
>    - 核心是基于非阻塞的 IO 多路复用机制
>    - 单线程反而避免了多线程的频繁上下文切换问题
>
> 3. **其他不同**
>    - 数据类型不同，redis有五种(list set string hash zset),memcached只有一种string
>    - Redis支持数据的备份，即master-slave模式的数据备份。
>    - Redis支持数据的持久化，可以将内存中的数据保持在磁盘中，重启的时候可以再次加载进行使用。
>    - 内存的使用率上memcached数据结构简单 只有一种string ,不用记录数据的类型。而reids需要记录。

## Redis常用数据类型

- 字符串(String)
- 字符串列表(list)
- 字符串集合(set)
- 哈希(hash)
- 有序的字符串集合(sorted set)

> #### 1.String
>
> > **常用命令:** set,get,decr,incr,mget 等。
>
> String数据结构是简单的key-value类型，value其实不仅可以是String，也可以是数字。
> 常规key-value缓存应用；
> 常规计数：微博数，粉丝数等。
>
> #### 2.Hash
>
> > **常用命令：** hget,hset,hgetall 等。
>
> hash 是一个 string 类型的 field 和 value 的映射表，hash 特别适合用于存储对象，后续操作的时候，你可以直接仅仅修改这个对象中的某个字段的值。 比如我们可以 hash 数据结构来存储用户信息，商品信息等等。比如下面我就用 hash 类型存放了我本人的一些信息：
>
> ```
> key=JavaUser293847
> value={
>   “id”: 1,
>   “name”: “SnailClimb”,
>   “age”: 22,
>   “location”: “Wuhan, Hubei”
> }
> ```
>
> #### 3.List
>
> > **常用命令:** lpush,rpush,lpop,rpop,lrange等
>
> list 是有序列表，这个可以玩出很多花样。
>
> list 就是链表，Redis list 的应用场景非常多，也是Redis最重要的数据结构之一，比如微博的关注列表，粉丝列表，消息列表等功能都可以用Redis的 list 结构来实现。
>
> Redis list 的实现为一个双向链表，即可以支持反向查找和遍历，更方便操作，不过带来了部分额外的内存开销。
>
> 另外可以通过 lrange 命令，就是从某个元素开始读取多少个元素，可以基于 list 实现分页查询，这个很棒的一个功能，基于 redis 实现简单的高性能分页，可以做类似微博那种下拉不断分页的东西（一页一页的往下走），性能高。
>
> #### 4.Set
>
> > **常用命令：**sadd,spop,smembers,sunion 等
>
> set 是无序集合，自动去重。
>
> set 对外提供的功能与list类似是一个列表的功能，特殊之处在于 set 是可以自动排重的。
>
> 当你需要存储一个列表数据，又不希望出现重复数据时，set是一个很好的选择，并且set提供了判断某个成员是否在一个set集合内的重要接口，这个也是list所不能提供的。可以基于 set 轻易实现交集、并集、差集的操作。
>
> 比如：在微博应用中，可以将一个用户所有的关注人存在一个集合中，将其所有粉丝存在一个集合。Redis可以非常方便的实现如共同关注、共同粉丝、共同喜好等功能。这个过程也就是求交集的过程，具体命令如下：
>
> ```
> sinterstore key1 key2 key3     将交集存在key1内
> ```
>
> #### 5.Sorted Set
>
> > **常用命令：** zadd,zrange,zrem,zcard等
>
> 和set相比，sorted set增加了一个权重参数score，使得集合中的元素能够按score进行有序排列。
>
> **举例：** 在直播系统中，实时排行信息包含直播间在线用户列表，各种礼物排行榜，弹幕消息（可以理解为按消息维度的消息排行榜）等信息，适合使用 Redis 中的 Sorted Set 结构进行存储。

## Redis 的线程模型

> redis 内部使用文件事件处理器 `file event handler`，这个文件事件处理器是单线程的，所以 redis 才叫做单线程的模型。它采用 IO 多路复用机制同时监听多个 socket，根据 socket 上的事件来选择对应的事件处理器进行处理。
>
> 文件事件处理器的结构包含 4 个部分：
>
> - 多个 socket
> - IO 多路复用程序
> - 文件事件分派器
> - 事件处理器（连接应答处理器、命令请求处理器、命令回复处理器）
>
> 多个 socket 可能会并发产生不同的操作，每个操作对应不同的文件事件，但是 IO 多路复用程序会监听多个 socket，会将 socket 产生的事件放入队列中排队，事件分派器每次从队列中取出一个事件，把该事件交给对应的事件处理器进行处理。

## Redis 设置过期时间

> Redis中有个设置时间过期的功能，即对存储在 redis 数据库中的值可以设置一个过期时间。作为一个缓存数据库，这是非常实用的。如我们一般项目中的 token 或者一些登录信息，尤其是短信验证码都是有时间限制的，按照传统的数据库处理方式，一般都是自己判断过期，这样无疑会严重影响项目性能。
>
> 我们 set key 的时候，都可以给一个 expire time，就是过期时间，通过过期时间我们可以指定这个 key 可以存活的时间。
>
> 如果假设你设置了一批 key 只能存活1个小时，那么接下来1小时后，redis是怎么对这批key进行删除的？
>
> **定期删除+惰性删除。**
>
> 通过名字大概就能猜出这两个删除方式的意思了。
>
> - **定期删除**：redis默认是每隔 100ms 就**随机抽取**一些设置了过期时间的key，检查其是否过期，如果过期就删除。注意这里是随机抽取的。为什么要随机呢？你想一想假如 redis 存了几十万个 key ，每隔100ms就遍历所有的设置过期时间的 key 的话，就会给 CPU 带来很大的负载！
> - **惰性删除** ：定期删除可能会导致很多过期 key 到了时间并没有被删除掉。所以就有了惰性删除。假如你的过期 key，靠定期删除没有被删除掉，还停留在内存里，除非你的系统去查一下那个 key，才会被redis给删除掉。这就是所谓的惰性删除，也是够懒的哈！
>
> 但是仅仅通过设置过期时间还是有问题的。我们想一下：如果定期删除漏掉了很多过期 key，然后你也没及时去查，也就没走惰性删除，此时会怎么样？如果大量过期key堆积在内存里，导致redis内存块耗尽了。怎么解决这个问题呢？ **redis 内存淘汰机制。**

## **Redis数据淘汰策略**

> 1. **volatile-lru**：从已设置过期时间的数据集（server.db[i].expires）中挑选最近最少使用的数据淘汰
> 2. **volatile-ttl**：从已设置过期时间的数据集（server.db[i].expires）中挑选将要过期的数据淘汰
> 3. **volatile-random**：从已设置过期时间的数据集（server.db[i].expires）中任意选择数据淘汰
> 4. **allkeys-lru**：当内存不足以容纳新写入数据时，在键空间中，移除最近最少使用的key（这个是最常用的）
> 5. **allkeys-random**：从数据集（server.db[i].dict）中任意选择数据淘汰
> 6. **no-eviction**：禁止驱逐数据，也就是说当内存不足以容纳新写入数据时，新写入操作会报错。这个应该没人使用吧！
>
> **4.0版本后增加以下两种：**
>
> 1. **volatile-lfu**：从已设置过期时间的数据集(server.db[i].expires)中挑选最不经常使用的数据淘汰
> 2. **allkeys-lfu**：当内存不足以容纳新写入数据时，在键空间中，移除最不经常使用的key

## Redis 持久化机制

### 什么叫持久化

> 用一句话可以将持久化概括为：将数据（如内存中的对象）保存到可永久保存的存储设备中。持久化的主要应用是将内存中的对象存储在数据库中，或者存储在磁盘文件中、 XML 数据文件中等等。
>
> > 从应用层与系统层理解持久化
>
> 同时，也可以从应用层和系统层这两个层面来理解持久化：
>
> **应用层**：如果关闭( `Close` )你的应用然后重新启动则先前的数据依然存在。
>
> **系统层**：如果关闭( `Shutdown` )你的系统（电脑）然后重新启动则先前的数据依然存在。

### 为什么要持久化

> Redis 中的数据类型都支持 push/pop、add/remove 及取交集并集和差集及更丰富的操作，而且这些操作都是原子性的。在此基础上，Redis 支持各种不同方式的排序。与 Memcached 一样，为了保证效率，数据都是缓存在内存中。
>
> 对，数据都是缓存在内存中的，当你重启系统或者关闭系统后，缓存在内存中的数据都会消失殆尽，再也找不回来了。所以，为了让数据能够长期保存，就要将 Redis 放在缓存中的数据做持久化存储。

### 怎么实现持久化

> 在设计之初，Redis 就已经考虑到了这个问题。官方提供了多种不同级别的数据持久化的方式：
> 1. RDB持久化方式能够在指定的时间间隔能对你的数据进行快照存储。
> 2. AOF持久化方式记录每次对服务器写的操作,当服务器重启的时候会重新执行这些命令来恢复原始的数据,AOF命令以redis协议追加保存每次写的操作到文件末尾.Redis还能对AOF文件进行后台重写,使得AOF文件的体积不至于过大。
> 3. 如果你只希望你的数据在服务器运行的时候存在,你也可以不使用任何持久化方式。
> 4. 你也可以同时开启两种持久化方式, 在这种情况下, 当redis重启的时候会优先载入AOF文件来恢复原始的数据,因为在通常情况下AOF文件保存的数据集要比RDB文件保存的数据集要完整。
>
> 如果你不知道该选择哪一个级别的持久化方式，那我们就先来了解一下 AOF 方式和 RDB 方式有什么样的区别，并且它们各自有何优劣，学习完之后，再来考虑该选择哪一种级别。

### RDB 与 AOF 方式的优势对比

#### RDB 方式的优点

> - RDB 是一个非常紧凑的文件,它保存了某个时间点的数据集,非常适用于数据集的备份,比如你可以在每个小时报保存一下过去24小时内的数据,同时每天保存过去30天的数据,这样即使出了问题你也可以根据需求恢复到不同版本的数据集。
> - RDB 是一个紧凑的单一文件,很方便传送到另一个远端数据中心，非常适用于灾难恢复。
> - RDB 在保存 RDB 文件时父进程唯一需要做的就是 fork 出一个子进程,接下来的工作全部由子进程来做，父进程不需要再做其他 IO 操作，所以 RDB 持久化方式可以最大化 Redis 的性能。
> - 与AOF相比,在恢复大的数据集的时候，RDB 方式会更快一些。
>
> 当 Redis 需要保存 `dump.rdb` 文件时， 服务器执行以下操作:
>
> - Redis 调用forks. 同时拥有父进程和子进程。
> - 子进程将数据集写入到一个临时 RDB 文件中。
> - 当子进程完成对新 RDB 文件的写入时，Redis 用新 RDB 文件替换原来的 RDB 文件，并删除旧的 RDB 文件。
>
> 这种工作方式使得 Redis 可以从写时复制（`copy-on-write`）机制中获益。

#### AOF 方式的优点

> 使用AOF 会让你的Redis更加耐久:
>
> - 你可以使用不同的 fsync 策略：无 fsync、每秒 fsync 、每次写的时候 fsync .使用默认的每秒 fsync 策略, Redis 的性能依然很好( fsync 是由后台线程进行处理的,主线程会尽力处理客户端请求),一旦出现故障，你最多丢失1秒的数据。
> - AOF文件是一个只进行追加的日志文件,所以不需要写入seek,即使由于某些原因(磁盘空间已满，写的过程中宕机等等)未执行完整的写入命令,你也也可使用redis-check-aof工具修复这些问题。
> - Redis 可以在 AOF 文件体积变得过大时，自动地在后台对 AOF 进行重写： 重写后的新 AOF 文件包含了恢复当前数据集所需的最小命令集合。 整个重写操作是绝对安全的，因为 Redis 在创建新 AOF 文件的过程中，会继续将命令追加到现有的 AOF 文件里面，即使重写过程中发生停机，现有的 AOF 文件也不会丢失。 而一旦新 AOF 文件创建完毕，Redis 就会从旧 AOF 文件切换到新 AOF 文件，并开始对新 AOF 文件进行追加操作。
> - AOF 文件有序地保存了对数据库执行的所有写入操作， 这些写入操作以 Redis 协议的格式保存， 因此 AOF 文件的内容非常容易被人读懂， 对文件进行分析（`parse`）也很轻松。 导出（`export`） AOF 文件也非常简单： 举个例子， 如果你不小心执行了 FLUSHALL 命令， 但只要 AOF 文件未被重写， 那么只要停止服务器， 移除 AOF 文件末尾的 FLUSHALL 命令， 并重启 Redis ， 就可以将数据集恢复到 FLUSHALL 执行之前的状态。

#### 优点对比总结

> RDB 方式可以保存过去一段时间内的数据，并且保存结果是一个单一的文件，可以将文件备份到其他服务器，并且在回复大量数据的时候，RDB 方式的速度会比 AOF 方式的回复速度要快。
>
> AOF 方式默认每秒钟备份1次，频率很高，它的操作方式是以追加的方式记录日志而不是数据，并且它的重写过程是按顺序进行追加，所以它的文件内容非常容易读懂。可以在某些需要的时候打开 AOF 文件对其编辑，增加或删除某些记录，最后再执行恢复操作。

#### 缺点对比总结

> RDB 方式的缺点
>
> - 如果你希望在 Redis 意外停止工作（例如电源中断）的情况下丢失的数据最少的话，那么 RDB 不适合你.虽然你可以配置不同的`save`时间点(例如每隔 5 分钟并且对数据集有 100 个写的操作),是 Redis 要完整的保存整个数据集是一个比较繁重的工作,你通常会每隔5分钟或者更久做一次完整的保存,万一在 Redis 意外宕机,你可能会丢失几分钟的数据。
> - RDB 需要经常 fork 子进程来保存数据集到硬盘上,当数据集比较大的时候, fork 的过程是非常耗时的,可能会导致 Redis 在一些毫秒级内不能响应客户端的请求。如果数据集巨大并且 CPU 性能不是很好的情况下,这种情况会持续1秒, AOF 也需要 fork ,但是你可以调节重写日志文件的频率来提高数据集的耐久度。
>
> AOF 方式的缺点
>
> - 对于相同的数据集来说，AOF 文件的体积通常要大于 RDB 文件的体积。
> - 根据所使用的 fsync 策略，AOF 的速度可能会慢于 RDB 。 在一般情况下， 每秒 fsync 的性能依然非常高， 而关闭 fsync 可以让 AOF 的速度和 RDB 一样快， 即使在高负荷之下也是如此。 不过在处理巨大的写入载入时，RDB 可以提供更有保证的最大延迟时间（`latency`）。
>
> 对比总结
>
> - RDB 由于备份频率不高，所以在回复数据的时候有可能丢失一小段时间的数据，而且在数据集比较大的时候有可能对毫秒级的请求产生影响。
> - AOF 的文件提及比较大，而且由于保存频率很高，所以整体的速度会比 RDB 慢一些，但是性能依旧很高。

### 工作原理

> AOF 重写和 RDB 创建快照一样，都巧妙地利用了写时复制机制:
>
> - Redis 执行 fork() ，现在同时拥有父进程和子进程。
> - 子进程开始将新 AOF 文件的内容写入到临时文件。
> - 对于所有新执行的写入命令，父进程一边将它们累积到一个内存缓存中，一边将这些改动追加到现有 AOF 文件的末尾,这样样即使在重写的中途发生停机，现有的 AOF 文件也还是安全的。
> - 当子进程完成重写工作时，它给父进程发送一个信号，父进程在接收到信号之后，将内存缓存中的所有数据追加到新 AOF 文件的末尾。
> - 现在 Redis 原子地用新文件替换旧文件，之后所有命令都会直接追加到新 AOF 文件的末尾。

### 优先选择 RDB 还是 AOF ？

> - 对于企业级的中大型应用，如果不想牺牲数据完整性但是又希望保持高效率，那么你应该同时使用 RDB 和 AOF 两种方式；
> - 如果你不打算耗费精力在这个地方，只需要保证数据完整性，那么优先考虑使用 AOF 方式；
> - RDB 方式非常适合大规模的数据恢复，如果业务对数据完整性和一致性要求不高，RDB是很好的选择。

### 备份redis数据的建议

> 确保你的数据有完整的备份，磁盘故障、节点失效等问题问题可能让你的数据消失不见， 不进行备份是非常危险的。
>
> Redis 对于数据备份是非常友好的， 因为你可以在服务器运行的时候对 RDB 文件进行复制： RDB 文件一旦被创建， 就不会进行任何修改。 当服务器要创建一个新的 RDB 文件时， 它先将文件的内容保存在一个临时文件里面， 当临时文件写入完毕时， 程序才使用 `rename(2)` 原子地用临时文件替换原来的 RDB 文件。
>
> 这也就是说，无论何时，复制 RDB 文件都是绝对安全的。
>
> - 创建一个定期任务（ cron job ）， 每小时将一个 RDB 文件备份到一个文件夹， 并且每天将一个 RDB 文件备份到另一个文件夹。
> - 确保快照的备份都带有相应的日期和时间信息， 每次执行定期任务脚本时， 使用 `find` 命令来删除过期的快照： 比如说， 你可以保留最近 48 小时内的每小时快照， 还可以保留最近一两个月的每日快照。
> - 至少每天一次， 将 RDB 备份到你的数据中心之外， 或者至少是备份到你运行 Redis 服务器的物理机器之外。

## 缓存四大问题

### 缓存雪崩

> 数据未加载到缓存中，或者缓存同一时间大面积的失效，从而导致所有请求都去查数据库，导致数据库CPU和内存负载过高，甚至宕机。
>
> 解决方案：
>
> 1. 缓存层设计成高可用，防止缓存大面积故障。
>
> 2. 缓存降级：对源服务访问进行限流、资源隔离（熔断），降级的最终目的是保证核心服务可用，即使是有损的。
>    - 一般：比如有些服务偶尔因为网络抖动或者服务正在上线而超时，可以自动降级；
>    - 警告：有些服务在一段时间内成功率有波动（如在95~100%之间），可以自动降级或人工降级，并发送告警；
>    - 错误：比如可用率低于90%，或者数据库连接池被打爆了，或者访问量突然猛增到系统能承受的最大阀值，此时可以根据情况自动降级或者人工降级；
>    - 严重错误：比如因为特殊原因数据错误了，此时需要紧急人工降级。
> 3. Redis备份和快速缓存预热；
>
> 4. 提前演练

### 缓存穿透

> 缓存穿透是指查询一个一不存在的数据。例如：从缓存redis没有命中，需要从mysql数据库查询，查不到数据则不写入缓存，这将导致这个不存在的数据每次请求都要到数据库去查询，造成缓存穿透。一般存在于恶意访问或服务被攻击；
>
> 解决思路：
>
> 如果查询数据库也为空，直接设置一个默认值存放到缓存，这样第二次到缓冲中获取就有值了，而不会继续访问数据库。设置一个过期时间或者当有值的时候将缓存中的值替换掉即可。可以给key设置一些格式规则，然后查询之前先过滤掉不符合规则的Key。

### 缓存击穿

> 是指一个key非常热点，在不停的扛着大并发，大并发集中对这一个点进行访问，当这个key在失效的瞬间，持续的大并发就穿破缓存，直接请求数据库，就像在一个屏障上凿开了一个洞。
>
> 解决方案：
>
> 1. 设置热点数据永远不过期。
>
> 2. 加互斥锁

### 缓存预热

> 缓存预热就是系统上线后，将相关的缓存数据直接加载到缓存系统。这样就可以避免在用户请求的时候，先查询数据库，然后再将数据缓存的问题！用户直接查询事先被预热的缓存数据！
>
> 解决思路：
>
> 1. 直接写个缓存刷新页面，上线时手工操作下；
>
> 2. 数据量不大，可以在项目启动的时候自动进行加载，目的就是在系统上线前，将数据加载到缓存中。

## 哨兵模式

哨兵，英文名 Sentinel，是一个分布式系统，用于对主从结构中的每一台服务器进行监控，当主节点出现故障后通过投票机制来挑选新的主节点，并且将所有的从节点连接到新的主节点上。

### 简单理解

> 首先进行监控，并且所有的哨兵同步信息。
>
> 哨兵向订阅里边发布信息。
>
> 故障转移：哨兵发现主节点下线→哨兵开启投票竞选负责人→由负责人推选新的主节点→新的主节点断开原主节点，并且其他的从节点连接新的主节点，原主节点上线后作为从节点连接。
>
> 1. 三个定时任务
>
>    - 每10秒每个 sentinel 对master 和 slave 执行info 命令:该命令第一个是用来发现slave节点,第二个是确定主从关系.
>    - 每2秒每个 sentinel 通过 master 节点的 channel(名称为_sentinel_:hello) 交换信息(pub/sub):用来交互对节点的看法(后面会介绍的节点主观下线和客观下线)以及自身信息.
>    - 每1秒每个 sentinel 对其他 sentinel 和 redis 执行 ping 命令,用于心跳检测,作为节点存活的判断依据.
>
> 2. 主观下线和客观下线
>
>    - 主观下线
>      SDOWN:subjectively down,直接翻译的为”主观”失效,即当前sentinel实例认为某个redis服务为”不可用”状态.
>
>    - 客观下线
>      ODOWN:objectively down,直接翻译为”客观”失效,即多个sentinel实例都认为master处于”SDOWN”状态,那么此时master将处于ODOWN,ODOWN可以		简单理解为master已经被集群确定为”不可用”,将会开启故障转移机制.
>
> 3. 故障转移
>
>   - 哨兵发现主节点下线→哨兵开启投票竞选负责人→由负责人推选新的主节点→新的主节点断开原主节点，并且其他的从节点连接新的主节点，原主节点上线后作为从节点连接。

### 主要功能

- 监控  检查主从服务节点是否服务正常
- 提醒 当被监控的节点出现问题时，哨兵机制可以发送通知
- 自动故障转移 主节点不可以用时，自动进行节点升级和故障转移。
- 提供配置 作为客户端的配置提供者。

### 故障转移流程

- 每个Sentinel每秒钟向主节点、从节点、其他sentinel实例发送PING命令。
- 如果一个Sentinel发现主服务节点不可用，会将主节点标记为主观下线，并通知其他Sentinel实例向主节点发送消息。
- 如果有足够数量的Sentinel实例，满足配置文件中需要的个数`sentinel monitor mymaster 127.0.0.1 6379 2` 这里配置的是2，那就将主服务标记为客观下线。
- Sentinel通过选举机制选举出一个Lead Sentinel，负责本次故障转移。
- Sentinle选择一个从服务节点，向其发送SALVE NO ONE 命令，使其升级为主节点。
- 通过发布与订阅功能， 将更新后的配置传播给所有其他 Sentinel ， 其他 Sentinel 对它们自己的配置进行更新。
- 向从服务器发送 [SLAVEOF] 命令，让他们的主服务节点更新为上一步新主节点。
- 当所有从服务器都已经开始复制新的主服务器时， 复制本次故障转移的Sentinel 终止这次故障迁移操作。

### 注意要点

- Sentinel会在运行中自动的修改配置文件并进行持久化，主要涉及主从配置点。
- 每一次故障转移Sentinel都会用过选举机制选举从本次故障转移的领头Sentinel，从而有领头的Sentinel来负责故障转移过程。
- Sentinel之间通过订阅发布来进行消息传输。
- Sentinel机制很大程度依赖计算机时间，如果计算机出现故障，或者进程被阻塞，Sentinel可能也会出现故障，从而进入TLTL保护模式，进入TILT模式后，哨兵就不会在起作用。如果在30S内恢复正常，就会退出TITL模式。

# Nginx

## 概念

> - Nginx是一个 轻量级/高性能的反向代理Web服务器，他实现非常高效的反向代理、负载平衡，他可以处理2-3万并发连接数，官方监测能支持5万并发，现在中国使用nginx网站用户有很多，例如：新浪、网易、 腾讯等。

## 作用

> 1.反向代理　　2.负载均衡　　3.HTTP服务器（包含动静分离）　　4.正向代理
>
> **正向代理:**
>
> 在客户端(浏览器)配置代理服务器，通过代理服务器进行互联网访问。
>
> **反向代理**
>
> 我们只需要将请求发送到反向代理服务器，由反向代理服务器去选择目标服务器获取数据后，在返回给客户端，此时反向代理服务器和目标服务器对外就是一个服务器,暴露的是代理服务器地址，隐藏了真实服务器IP地址。
>
> **负载均衡**
>
> 单个服务器解决不了，我们增加服务器的数量，然后将请求分发到各个服务器上，将原先请求集中到单个服务器上的情况改为将请求分发到多个服务器上，将负载分发到不同的服务器，也就是我们所说的负载均衡。
>
> **动静分离**
>
> 为了加快网站的解析速度，可以把动态页面和静态页面由不同的服务器来解析，加快解析速度。降低原来单个服务器的压力。

## 特性

> - 跨平台：可以在大多数Unix like 系统编译运行。而且也有Windows的移植版本。 
> - 配置异常简单：非常的简单，易上手。 
> - 非阻塞、高并发连接：数据复制时，磁盘I/O的第一阶段是非阻塞的。官方测试能支持5万并发连接，实际生产中能跑2~3万并发连接数（得益于Nginx采用了最新的epoll事件处理模型（消息队列）。 
> - Nginx代理和后端Web服务器间无需长连接； 
> - Nginx接收用户请求是异步的，即先将用户请求全部接收下来，再一次性发送到后端Web服务器，极大减轻后端Web服务器的压力。 
> - 发送响应报文时，是边接收来自后端Web服务器的数据，边发送给客户端。 
> - 网络依赖性低，理论上只要能够ping通就可以实施负载均衡，而且可以有效区分内网、外网流量。 
> - 支持内置服务器检测。Nginx能够根据应用服务器处理页面返回的状态码、超时信息等检测服务器是否出现故障，并及时返回错误的请求重新提交到其它节点上。 
> - 此外还有内存消耗小、成本低廉（比F5硬件负载均衡器廉价太多）、节省带宽、稳定性高等特点。

## 与apache的区别

> 轻量级，同样起web 服务，比apache 占用更少的内存及资源
> 抗并发，nginx 处理请求是异步非阻塞的，而apache 则是阻塞型的，在高并发下nginx 能保持低资源低消耗高性能
> 高度模块化的设计，编写模块相对简单
> 最核心的区别在于apache是同步多进程模型，一个连接对应一个进程；nginx是异步的，多个连接（万级别）可以对应一个进程

## Nginx负载均衡算法

> **1、轮询（默认调度算法）**
>
> 特点：每个请求按时间顺序逐一分配到不同的后端服务器处理。
> 适用业务场景：后端服务器硬件性能配置完全一致，业务无特殊要求时使用。
>
> ```
> upstream backendserver { 
> server 192.168.0.14：80 max_fails=2 fail_timeout=10s; 
> server 192.168.0.15：80 max_fails=2 fail_timeout=10s; 
> }
> ```
>
> **2、加权轮询**
>
> 特点：指定轮询几率，weight值(权重)和访问比例成正比，用户请求按权重比例分配。
> 适用业务场景：用于后端服务器硬件性处理能力不平均的情形。
>
> ```
> upstream backendserver { 
> server 192.168.0.14:80 weight=5 max_fails=2 fail_timeout=10s; 
> server 192.168.0.15:80 weight=10 max_fails=2 fail_timeout=10s;
> }
> ```
>
> **3、ip_hash**
>
> 特点：每个请求按访问ip的hash结果分配，这样每个访客固定访问一个后端服务器，可以解决session会话保持问题。
> 适用业务场景：适用于需要账号登录的系统，会话连接保持的业务。
>
> ```
> upstream backendserver { 
> ip_hash; 
> server 192.168.0.14:80 max_fails=2 fail_timeout=10s; 
> server 192.168.0.15:80 max_fails=2 fail_timeout=10s; 
> } 
> ```
>
> **4、最少连接数 least_conn**
>
> 特点：按nginx反向代理与后端服务器之间的连接数，连接数最少的优先分配。
> 适用业务场景：适用于客户端与后端服务器需要保持长连接的业务。
>
> ```
> upstream backendserver { 
> least_conn;
> server 192.168.0.14:80 max_fails=2 fail_timeout=10s; 
> server 192.168.0.15:80 max_fails=2 fail_timeout=10s; 
> } 
> ```
>
> **5、fair（需编译安装第三方模块 ngx_http_upstream_fair_module）**
>
> 特点：按后端服务器的响应时间来分配请求，响应时间短的优先分配。
> 适用业务场景：对访问响应速度有一定要求的业务。
>
> ```
> upstream backendserver {
> fair; 
> server 192.168.0.14:80 max_fails=2 fail_timeout=10s; 
> server 192.168.0.15:80 max_fails=2 fail_timeout=10s; 
> }
> ```
>
> **6、url_hash（需编译安装第三方模块 ngx_http_upstream_hash_module）**
>
> 特点：按访问url的hash结果来分配请求，使同一个url访问到同一个后端服务器。
> 适用业务场景：适用于后端服务器为缓存服务器时比较有效。
>
> ```
> upstream backendserver { 
> server 192.168.0.14:80 max_fails=2 fail_timeout=10s;
> server 192.168.0.15:80 max_fails=2 fail_timeout=10s; 
> hash $request_uri; 
> }
> ```

## 为什么选择Nginx

> - 跨平台、配置简单
> - 非阻塞、高并发连接：
>   处理2-3万并发连接数，官方监测能支持5万并发
> - 内存消耗小：
>   开启10个nginx才占150M内存，Nginx采取了分阶段资源分配技术
> - nginx处理静态文件好,耗费内存少
> - 内置的健康检查功能：
>   如果有一个服务器宕机，会做一个健康检查，再发送的请求就不会发送到宕机的服务器了。重新将请求提交到其他的节点上。
> - 节省宽带：
>   支持GZIP压缩，可以添加浏览器本地缓存
> - 稳定性高：
>   宕机的概率非常小
> - master/worker结构：
>   一个master进程，生成一个或者多个worker进程
> - 接收用户请求是异步的：
>   浏览器将请求发送到nginx服务器，它先将用户请求全部接收下来，再一次性发送给后端web服务器，极大减轻了web服务器的压力,一边接收web服务器的返回数据，一边发送给浏览器客户端
> - 网络依赖性比较低，只要ping通就可以负载均衡
> - 可以有多台nginx服务器

## nginx如何处理请求

- nginx接收一个请求后，首先由listen和server_name指令匹配server模块，再匹配server模块里的location，location就是实际地址

```nginx
server {            						# 第一个Server区块开始，表示一个独立的虚拟主机站点
    listen       80；      					# 提供服务的端口，默认80
    server_name  localhost；       			# 提供服务的域名主机名
    location / {            			# 第一个location区块开始
    root   html；       					# 站点的根目录，相当于Nginx的安装目录
    index  index.html index.htm；      	# 默认的首页文件，多个用空格分开
    }   
```

## 什么是正向代理和反向代理

1. 正向代理就是一个人发送一个请求直接就到达了目标的服务器
2. 反方代理就是请求统一被Nginx接收，nginx反向代理服务器接收到之后，按照一定的规 则分发给了后端的业务处理服务器进行处理了

> **反向代理服务器的优点**
>
> - 反向代理服务器可以隐藏源服务器的存在和特征。它充当互联网云和web服务器之间的中间层。这对于安全方面来说是很好的，特别是当您使用web托管服务时。

## Nginx的优缺点？

> - 优点：
>   1. 占内存小，可实现高并发连接，处理响应快
>   2. 可实现http服务器、虚拟主机、方向代理、负载均衡
>   3. Nginx配置简单
>   4. 可以不暴露正式的服务器IP地址
> - 缺点：
>   动态处理差：nginx处理静态文件好,耗费内存少，但是处理动态页面则很鸡肋，现在一般前端用nginx作为反向代理抗住压力，

## Nginx应用场景

> 1. http服务器。Nginx是一个http服务可以独立提供http服务。可以做网页静态服务器。
> 2. 虚拟主机。可以实现在一台服务器虚拟出多个网站，例如个人网站使用的虚拟机。
> 3. 反向代理，负载均衡。当网站的访问量达到一定程度后，单台服务器不能满足用户的请求时，需要用多台服务器集群可以使用nginx做反向代理。并且多台服务器可以平均分担负载，不会应为某台服务器负载高宕机而某台服务器闲置的情况。
> 4. nginz 中也可以配置安全管理、比如可以使用Nginx搭建API接口网关,对每个接口服务进行拦截。

## nginx.conf有哪些属性模块

~~~nginx
worker_processes  1；                					# worker进程的数量
events {                              					# 事件区块开始
    worker_connections  1024；            				# 每个worker进程支持的最大连接数
}                                    					# 事件区块结束
http {                               					# HTTP区块开始
    include       mime.types；            				# Nginx支持的媒体类型库文件
    default_type  application/octet-stream；     		# 默认的媒体类型
    sendfile        on；       							# 开启高效传输模式
    keepalive_timeout  65；       						# 连接超时
    server {            								# 第一个Server区块开始，表示一个独立的虚拟主机站点
        listen       80；      							# 提供服务的端口，默认80
        server_name  localhost；       					# 提供服务的域名主机名
        location / {            						# 第一个location区块开始
            root   html；       						# 站点的根目录，相当于Nginx的安装目录
            index  index.html index.htm；      			# 默认的首页文件，多个用空格分开
        }          										# 第一个location区块结果
        error_page   500502503504  /50x.html；     		# 出现对应的http状态码时，使用50x.html回应客户
        location = /50x.html {          				# location区块开始，访问50x.html
            root   html；      							# 指定对应的站点目录为html
        }
    }  
    ......
~~~

## Nginx静态资源?

- 静态资源访问，就是存放在nginx的html页面，我们可以自己编写

## 如何用Nginx解决前端跨域问题？

- 使用Nginx转发请求。把跨域的接口写成调本域的接口，然后将这些接口转发到真正的请求地址。

## Nginx虚拟主机怎么配置?

- 1、基于域名的虚拟主机，通过域名来区分虚拟主机——应用：外部网站
- 2、基于端口的虚拟主机，通过端口来区分虚拟主机——应用：公司内部网站，外部网站的管理后台
- 3、基于ip的虚拟主机。

## 限流怎么做的？

- Nginx限流就是限制用户请求速度，防止服务器受不了
- 限流有3种
  1. 正常限制访问频率（正常流量）
  2. 突发限制访问频率（突发流量）
  3. 限制并发连接数
- Nginx的限流都是基于漏桶流算法，底下会说道什么是漏桶算法


> **实现三种限流算法**
>
> ##### 1、正常限制访问频率（正常流量）：
>
> - 限制一个用户发送的请求，我Nginx多久接收一个请求。
> - Nginx中使用ngx_http_limit_req_module模块来限制的访问频率，限制的原理实质是基于漏桶算法原理来实现的。在nginx.conf配置文件中可以使用limit_req_zone命令及limit_req命令限制单个IP的请求处理频率。
>
> ```
> #定义限流维度，一个用户一分钟一个请求进来，多余的全部漏掉
> limit_req_zone $binary_remote_addr zone=one:10m rate=1r/m;
> 
> #绑定限流维度
> server{
> 
> location/seckill.html{
> limit_req zone=zone;	
> proxy_pass http://lj_seckill;
> }
> 
> }
> ```
>
> - 1r/s代表1秒一个请求，1r/m一分钟接收一个请求， 如果Nginx这时还有别人的请求没有处理完，Nginx就会拒绝处理该用户请求。
>
> ##### 2、突发限制访问频率（突发流量）：
>
> - 限制一个用户发送的请求，我Nginx多久接收一个。
> - 上面的配置一定程度可以限制访问频率，但是也存在着一个问题：如果突发流量超出请求被拒绝处理，无法处理活动时候的突发流量，这时候应该如何进一步处理呢？Nginx提供burst参数结合nodelay参数可以解决流量突发的问题，可以设置能处理的超过设置的请求数外能额外处理的请求数。我们可以将之前的例子添加burst参数以及nodelay参数：
>
> ```java
> #定义限流维度，一个用户一分钟一个请求进来，多余的全部漏掉
>     limit_req_zone $binary_remote_addr zone=one:10m rate=1r/m;
> 
> #绑定限流维度
>     server{
> 
>     location/seckill.html{
>         limit_req zone=zone burst=5 nodelay;
>         proxy_pass http://lj_seckill;
>     }
> 
> }
> ```
>
> - 为什么就多了一个 burst=5 nodelay; 呢，多了这个可以代表Nginx对于一个用户的请求会立即处理前五个，多余的就慢慢来落，没有其他用户的请求我就处理你的，有其他的请求的话我Nginx就漏掉不接受你的请求
>
> ##### 3、 限制并发连接数
>
> - Nginx中的ngx_http_limit_conn_module模块提供了限制并发连接数的功能，可以使用limit_conn_zone指令以及limit_conn执行进行配置。接下来我们可以通过一个简单的例子来看下：
>
> ```java
> http {
>     limit_conn_zone $binary_remote_addr zone=myip:10m;
>     limit_conn_zone $server_name zone=myServerName:10m;
> }
> 
> server {
>     location / {
>         limit_conn myip 10;
>         limit_conn myServerName 100;
>         rewrite / http://www.lijie.net permanent;
>     }
> }
> ```
>
> - 上面配置了单个IP同时并发连接数最多只能10个连接，并且设置了整个虚拟服务器同时最大并发数最多只能100个链接。当然，只有当请求的header被服务器处理后，虚拟服务器的连接数才会计数。刚才有提到过Nginx是基于漏桶算法原理实现的，实际上限流一般都是基于漏桶算法和令牌桶算法实现的。
>
> ### 漏桶流算法和令牌桶算法知道？
>
> #### 漏桶算法
>
> - 漏桶算法是网络世界中流量整形或速率限制时经常使用的一种算法，它的主要目的是控制数据注入到网络的速率，平滑网络上的突发流量。漏桶算法提供了一种机制，通过它，突发流量可以被整形以便为网络提供一个稳定的流量。也就是我们刚才所讲的情况。漏桶算法提供的机制实际上就是刚才的案例：**突发流量会进入到一个漏桶，漏桶会按照我们定义的速率依次处理请求，如果水流过大也就是突发流量过大就会直接溢出，则多余的请求会被拒绝。所以漏桶算法能控制数据的传输速率。**
>   ![在这里插入图片描述](https://img-blog.csdnimg.cn/20200411193924521.jpg)
>
> #### 令牌桶算法
>
> - 令牌桶算法是网络流量整形和速率限制中最常使用的一种算法。典型情况下，令牌桶算法用来控制发送到网络上的数据的数目，并允许突发数据的发送。Google开源项目Guava中的RateLimiter使用的就是令牌桶控制算法。**令牌桶算法的机制如下：存在一个大小固定的令牌桶，会以恒定的速率源源不断产生令牌。如果令牌消耗速率小于生产令牌的速度，令牌就会一直产生直至装满整个令牌桶。**
>
> ![在这里插入图片描述](https://img-blog.csdnimg.cn/20200411193930872.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MzEyMjA5MA==,size_16,color_FFFFFF,t_70)

## 为什么要做动静分离？

> - Nginx是当下最热的Web容器，网站优化的重要点在于静态化网站，网站静态化的关键点则是是动静分离，动静分离是让动态网站里的动态网页根据一定规则把不变的资源和经常变的资源区分开来，动静资源做好了拆分以后，我们则根据静态资源的特点将其做缓存操作。
> - 让静态的资源只走静态资源服务器，动态的走动态的服务器
> - Nginx的静态处理能力很强，但是动态处理能力不足，因此，在企业中常用动静分离技术。
> - 对于静态资源比如图片，js，css等文件，我们则在反向代理服务器nginx中进行缓存。这样浏览器在请求一个静态资源时，代理服务器nginx就可以直接处理，无需将请求转发给后端服务器tomcat。
>   若用户请求的动态文件，比如servlet,jsp则转发给Tomcat服务器处理，从而实现动静分离。这也是反向代理服务器的一个重要的作用。